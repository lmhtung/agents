{
  "page_content": "## LLM Provider Configuration  \nThis system is provider-agnostic — it supports any LLM provider available in [LangChain](https://python.langchain.com/docs/integrations/chat/), swappable in a single line. The examples below cover the most common options, but the same pattern applies to any other supported provider.  \n> **Note:** Model names change frequently. Always check the official documentation for the latest available models and their identifiers before deploying.\n\n### Ollama (Local)  \n```bash\n# Install Ollama from https://ollama.com\nollama pull qwen3:4b-instruct-2507-q4_K_M\n```  \n```python\nfrom langchain_ollama import ChatOllama\n\nllm = ChatOllama(model=\"qwen3:4b-instruct-2507-q4_K_M\", temperature=0)\n```\n> ⚠️ For reliable tool calling and instruction following, prefer models **7B+**. Smaller models may ignore retrieval instructions or hallucinate. See [Troubleshooting](#troubleshooting).  \n---\n\n### Cloud Providers  \n<details>\n<summary>Click to expand</summary>  \n**OpenAI GPT:**\n```bash\npip install -qU langchain-openai\n```\n```python\nfrom langchain_openai import ChatOpenAI\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\nllm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n```  \n**Anthropic Claude:**\n```bash\npip install -qU langchain-anthropic\n```\n```python\nfrom langchain_anthropic import ChatAnthropic\nimport os\n\nos.environ[\"ANTHROPIC_API_KEY\"] = \"your-api-key-here\"\nllm = ChatAnthropic(model=\"claude-sonnet-4-5-20250929\", temperature=0)\n```  \n**Google Gemini**\n```bash\npip install -qU langchain-google-genai\n```\n```python\nimport os\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\nos.environ[\"GOOGLE_API_KEY\"] = \"your-api-key-here\"\nllm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0)\n```\n</details>  \n---\n\n## Implementation  \nAdditional details and extended explanations are available in the **[notebook](Agentic_Rag_For_Dummies.ipynb)**.\n| Step | Description |\n|------|-------------|\n| 1 | [Initial Setup and Configuration](#step-1-initial-setup-and-configuration) |\n| 2 | [Configure Vector Database](#step-2-configure-vector-database) |\n| 3 | [PDFs to Markdown](#step-3-pdfs-to-markdown) |\n| 4 | [Hierarchical Document Indexing](#step-4-hierarchical-document-indexing) |\n| 5 | [Define Agent Tools](#step-5-define-agent-tools) |\n| 6 | [Define System Prompts](#step-6-define-system-prompts) |\n| 7 | [Define State and Data Models](#step-7-define-state-and-data-models) |\n| 8 | [Agent Configuration](#step-8-agent-configuration) |\n| 9 | [Build Graph Node and Edge Functions](#step-9-build-graph-node-and-edge-functions) |\n| 10 | [Build the LangGraph Graphs](#step-10-build-the-langgraph-graphs) |\n| 11 | [Create Chat Interface](#step-11-create-chat-interface) |",
  "metadata": {
    "H2": "LLM Provider Configuration -> LLM Provider Configuration -> LLM Provider Configuration -> Implementation",
    "H3": "Ollama (Local) -> Cloud Providers",
    "source": "Instruct.pdf",
    "parent_id": "Instruct_parent_2"
  }
}