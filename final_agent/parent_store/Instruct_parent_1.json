{
  "page_content": "### What's inside  \n| Feature | Description |\n|---|---|\n| ðŸ” **Hierarchical Indexing** | Search small chunks for precision, retrieve large Parent chunks for context |\n| ðŸ’¬ **Conversation Memory** | Maintains context across questions for natural dialogue |\n| ðŸ”„ **Query Clarification** | Rewrites ambiguous queries or pauses to ask the user for details |\n| ðŸ¤– **Agent Orchestration** | LangGraph coordinates the full retrieval and reasoning workflow |\n| ðŸ”€ **Multi-Agent Map-Reduce** | Decomposes complex queries into parallel sub-queries |\n| âœ… **Self-Correction** | Re-queries automatically if initial results are insufficient |\n| ðŸ§  **Context Compression** | Keeps working memory lean across long retrieval loops |\n\n### ðŸŽ¯ Two Ways to Use This Repo  \n**1ï¸âƒ£ Learning Path: Interactive Notebook**  \nStep-by-step tutorial perfect for understanding core concepts. Start here if you're new to Agentic RAG or want to experiment quickly.  \n**2ï¸âƒ£ Building Path: Modular Project**  \nFlexible architecture where each component can be independently swapped â€” LLM provider, embedding model, PDF converter, agent workflow. One line to switch from Ollama to Anthropic, OpenAI, or Google.  \nSee [Modular Architecture](#modular-architecture) and [Installation & Usage](#installation--usage) to get started.\n\n## How It Works  \n### Document Preparation: Hierarchical Indexing  \nBefore queries can be processed, documents are split twice for optimal retrieval:  \n- **Parent Chunks**: Large sections based on Markdown headers (H1, H2, H3)\n- **Child Chunks**: Small, fixed-size pieces derived from parents  \nThis combines the **precision of small chunks** for search with the **contextual richness of large chunks** for answer generation.  \n---\n\n### Query Processing: Four-Stage Intelligent Workflow\n```\nUser Query â†’ Conversation Summary â†’ Query Rewriting â†’ Query Clarification â†’\nParallel Agent Reasoning â†’ Aggregation â†’ Final Response\n```  \n**Stage 1 â€” Conversation Understanding:** Analyzes recent history to extract context and maintain continuity across questions.  \n**Stage 2 â€” Query Clarification:** Resolves references (\"How do I update it?\" â†’ \"How do I update SQL?\"), splits multi-part questions into focused sub-queries, detects unclear inputs, and rewrites queries for optimal retrieval. Pauses for human input when clarification is needed.  \n**Stage 3 â€” Intelligent Retrieval (Multi-Agent Map-Reduce):** Spawns parallel agent subgraphs â€” one per sub-query. Each agent searches child chunks, fetches parent chunks for context, self-corrects if results are insufficient, compresses context to avoid redundant fetches, and falls back gracefully if the search budget is exhausted.  \n> **Example:** *\"What is JavaScript? What is Python?\"* â†’ 2 parallel agents execute simultaneously.  \n**Stage 4 â€” Response Generation:** Aggregates all agent responses into a single coherent answer.  \n---",
  "metadata": {
    "H2": "Overview -> Overview -> How It Works -> How It Works",
    "H3": "What's inside -> ðŸŽ¯ Two Ways to Use This Repo -> Document Preparation: Hierarchical Indexing -> Query Processing: Four-Stage Intelligent Workflow",
    "source": "Instruct.pdf",
    "parent_id": "Instruct_parent_1"
  }
}